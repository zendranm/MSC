{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VAE_v1.ipynb","provenance":[],"collapsed_sections":["CzPpqjB4XJMW","GQdysqlVB11L","uyYCnVSULd2b"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CzPpqjB4XJMW","colab_type":"text"},"source":["# Drive and GPU Connection"]},{"cell_type":"markdown","metadata":{"id":"7yDVpNGie-yB","colab_type":"text"},"source":["Run to connect with google drive to access data"]},{"cell_type":"code","metadata":{"id":"_CUcVRIaXOe6","colab_type":"code","outputId":"fa9a6c59-afee-4202-b58c-1371768ed281","executionInfo":{"status":"ok","timestamp":1591610965614,"user_tz":-120,"elapsed":21601,"user":{"displayName":"Michał Zendran","photoUrl":"https://lh4.googleusercontent.com/-EdIWItliYF8/AAAAAAAAAAI/AAAAAAAAGOc/mlyaLViln_w/s64/photo.jpg","userId":"03602240860466142034"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4bbPYYBUgTmz","colab_type":"text"},"source":["Verify GPU"]},{"cell_type":"code","metadata":{"id":"YYRUNyj5gU8C","colab_type":"code","outputId":"c402445f-220c-482c-df58-dfc9b0708680","executionInfo":{"status":"ok","timestamp":1585414590486,"user_tz":-60,"elapsed":1049,"user":{"displayName":"Michał Zendran","photoUrl":"https://lh4.googleusercontent.com/-EdIWItliYF8/AAAAAAAAAAI/AAAAAAAAGOc/mlyaLViln_w/s64/photo.jpg","userId":"03602240860466142034"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["import tensorflow as tf \n","tf.test.gpu_device_name()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"GQdysqlVB11L","colab_type":"text"},"source":["# Data preprocess and visualization"]},{"cell_type":"code","metadata":{"id":"hvSA0RTJBxVF","colab_type":"code","outputId":"4a3b6a78-a6a5-48e3-eaf8-8a3e680716c8","executionInfo":{"status":"ok","timestamp":1591610972119,"user_tz":-120,"elapsed":3311,"user":{"displayName":"Michał Zendran","photoUrl":"https://lh4.googleusercontent.com/-EdIWItliYF8/AAAAAAAAAAI/AAAAAAAAGOc/mlyaLViln_w/s64/photo.jpg","userId":"03602240860466142034"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras import Sequential, Input, Model\n","from tensorflow.keras.layers import Dense, Activation, Flatten, Reshape, Lambda\n","from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, MaxPooling2D\n","from tensorflow.keras.layers import LeakyReLU, Dropout\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from keras import backend as K\n","\n","def load_data(filename):\n","    with np.load(filename) as f:\n","        x_train, x_test = f['arr_0'], f['arr_1']\n","        y_train, y_test = f['arr_2'], f['arr_3']\n","        return (x_train, y_train), (x_test, y_test)\n","\n","def preprocess_data(data, feature_range=(-1.0, 1.0)):\n","    (x_train, y_train), (x_test, y_test) = data\n","    min, max = feature_range\n","\n","    x_train = x_train.reshape(-1, 160, 160, 3).astype(np.float32)\n","    x_train = x_train/255.0\n","    x_train = x_train * (max - min) + min\n","\n","    x_test = x_test.reshape(-1, 160, 160, 3).astype(np.float32)\n","    x_test = x_test/255.0\n","    x_test = x_test * (max - min) + min\n","\n","    y_train = y_train.reshape(-1, 160, 160, 3).astype(np.float32)\n","    y_train = y_train/255.0\n","    y_train = y_train * (max - min) + min\n","\n","    y_test = y_test.reshape(-1, 160, 160, 3).astype(np.float32)\n","    y_test = y_test/255.0\n","    y_test = y_test * (max - min) + min\n","\n","    print(\"Values after preprocessing, min: \" + str(x_train.min()) + \", max: \" + str(x_train.max()))\n","    return (x_train, y_train), (x_test, y_test)\n","\n","def add_mirrored_data(data):\n","    (x_train, y_train), (x_test, y_test) = data\n","\n","    x_train_mirrored = np.flip(x_train, 2)\n","    y_train_mirrored = np.flip(y_train, 2)\n","    x_test_mirrored = np.flip(x_test, 2)\n","    y_test_mirrored = np.flip(y_test, 2)\n","\n","    x_train = np.concatenate((x_train, x_train_mirrored))\n","    y_train = np.concatenate((y_train, y_train_mirrored))\n","    x_test = np.concatenate((x_test, x_test_mirrored))\n","    y_test = np.concatenate((y_test, y_test_mirrored))\n","\n","    return (x_train, y_train), (x_test, y_test)\n","\n","def get_random_batch(data, batch_size):\n","    idx = np.random.choice(data.shape[0], batch_size)\n","    batch = data[idx].reshape((batch_size, 160, 160, 3))\n","    return batch\n","\n","def show_images(images, feature_range=(-1.0, 1.0)):\n","    min, max = feature_range\n","    plt.figure(figsize=(10,10))\n","    \n","    for im in range(images.shape[0]):\n","      plt.subplot(4, 4, im+1)\n","      image = images[im, :, :, :]\n","      image = np.reshape(image, [160,160,3])\n","      image = (image - min) / (max - min)\n","      plt.imshow(image)\n","      plt.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","\n","def visualize(sample_X, sample_Y, encoder, decoder, feature_range=(-1.0, 1.0)):\n","    min, max = feature_range\n","    count = sample_X.shape[0]\n","\n","    reconstructed_X = []\n","    reconstructed_Y = []\n","    accumulated = []\n","\n","    for n in range(count):\n","        code = encoder.predict(sample_X[n][None])[0]\n","        reco = decoder.predict(code[None])[0]\n","\n","        reconstructed_X.append(reco)\n","\n","        code = encoder.predict(sample_Y[n][None])[0]\n","        reco = decoder.predict(code[None])[0]\n","\n","        reconstructed_Y.append(reco)\n","\n","    for i in range(4):\n","        accumulated.append(sample_X[i])\n","        accumulated.append(reconstructed_X[i])\n","        accumulated.append(sample_Y[i])\n","        accumulated.append(reconstructed_Y[i])\n","\n","    count = len(accumulated)\n","\n","    plt.figure(figsize=(8,8))\n","\n","    for i in range(count):\n","        plt.subplot(4, 4, i + 1)\n","        image = (accumulated[i] - min) / (max - min)\n","        plt.imshow(image)\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"uyYCnVSULd2b","colab_type":"text"},"source":["# VAE networks"]},{"cell_type":"code","metadata":{"id":"7EIX3LfuLcmx","colab_type":"code","colab":{}},"source":["def sampling(args):\n","    mean_mu, log_var = args\n","    epsilon = tf.random.normal(shape=K.shape(mean_mu), mean=0., stddev=1.) \n","    return mean_mu + K.exp(log_var/2)*epsilon\n","\n","def build_encoder(img_shape, code_size):\n","    encoder_input = Input(shape=img_shape, name='encoder_input')\n","\n","    x = encoder_input\n","\n","    x = Conv2D(filters=32, kernel_size=(4, 4), strides=(2, 2), padding='same', name='encoder_conv_1')(x)\n","    x = LeakyReLU()(x)\n","\n","    x = Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2), padding='same', name='encoder_conv_2')(x)\n","    x = LeakyReLU()(x)\n","\n","    x = Conv2D(filters=128, kernel_size=(4, 4), strides=(2, 2), padding='same', name='encoder_conv_3')(x)\n","    x = LeakyReLU()(x)\n","\n","    x = Conv2D(filters=256, kernel_size=(4, 4), strides=(2, 2), padding='same', name='encoder_conv_4')(x)\n","    x = LeakyReLU()(x)\n","\n","    x = Flatten()(x)\n","\n","    mean_mu = Dense(code_size, name='mean_mu')(x)\n","    log_var = Dense(code_size, name='log_var')(x)\n","    encoder_output = Lambda(sampling, name='encoder_output')([mean_mu, log_var])\n","\n","    return encoder_input, encoder_output, mean_mu, log_var, Model(encoder_input, encoder_output)\n","\n","def build_decoder(img_shape, code_size):\n","    size1 = int(img_shape[0]/16) # 8 is 2^Conv2D in encoder\n","    size2 = int(img_shape[1]/16)\n","\n","    decoder_input = Input(shape=(int(code_size,)), name='decoder_input')\n","\n","    x = decoder_input\n","\n","    x = Dense(units=(size1*size2*256))(x)\n","    x = Reshape(target_shape=(size1, size2, 256))(x)\n","    \n","    x = Conv2DTranspose(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='same', name='decoder_conv_1')(x)\n","    x = LeakyReLU()(x)\n","\n","    x = Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same', name='decoder_conv_2')(x)\n","    x = LeakyReLU()(x)\n","\n","    x = Conv2DTranspose(filters=32, kernel_size=(3, 3), strides=(2, 2), padding='same', name='decoder_conv_3')(x)\n","    x = LeakyReLU()(x)\n","\n","    x = Conv2DTranspose(filters=3, kernel_size=(3, 3), strides=(2, 2), padding='same', name='decoder_conv_4')(x)\n","    x = Activation('tanh')(x)\n","\n","    decoder_output = x\n","\n","    return decoder_input, decoder_output, Model(decoder_input, decoder_output)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9nO6s4S5W3NO","colab_type":"text"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"OyD_5tRabmiC","colab_type":"code","outputId":"3db879e3-7415-4f6c-e4d8-cfe63718b018","executionInfo":{"status":"error","timestamp":1591611182990,"user_tz":-120,"elapsed":203924,"user":{"displayName":"Michał Zendran","photoUrl":"https://lh4.googleusercontent.com/-EdIWItliYF8/AAAAAAAAAAI/AAAAAAAAGOc/mlyaLViln_w/s64/photo.jpg","userId":"03602240860466142034"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1GFmNktyA3mIW4pldYbg3_cUgLoD6ecO5"}},"source":["tf.compat.v1.disable_eager_execution()\n","# Load and prepare data\n","npz_path = './drive/My Drive/ColabStuff/DiCaprioToDowneyJr_Big_VAE.npz'\n","(x_train, y_train), (x_test, y_test) = load_data(npz_path)\n","\n","value_range = (-1.0, 1.0)\n","print(\"Imported data shape: \" + str(x_train.shape))\n","\n","(x_train, y_train), (x_test, y_test) = preprocess_data(((x_train, y_train), (x_test, y_test)), value_range)\n","\n","# imported_data_sample = get_random_batch(x_train, 16)\n","# show_images(imported_data_sample, value_range)\n","\n","(x_train, y_train), (x_test, y_test) = add_mirrored_data(((x_train, y_train), (x_test, y_test)))\n","\n","# imported_data_sample = get_random_batch(x_train, 16)\n","# show_images(imported_data_sample, value_range)\n","\n","save_path = './drive/My Drive/ColabStuff/VAE/'\n","\n","train_x = np.concatenate((x_train, x_test))\n","train_y = np.concatenate((y_train, y_test))\n","\n","# # # # # # VAE training 1 # # # # # #\n","\n","IMG_SHAPE = x_train.shape[1:]\n","code_size = 200\n","epochs_number_1 =150\n","epochs_number_2 =800\n","LEARNING_RATE = 0.0005\n","LOSS_FACTOR = 1000\n","\n","vae_encoder_input, vae_encoder_output, mean_mu, log_var, vae_encoder = build_encoder(IMG_SHAPE, code_size)\n","# print(vae_encoder.summary())\n","\n","vae_decoder_input, vae_decoder_output, vae_decoder = build_decoder(IMG_SHAPE, code_size)\n","# print(vae_decoder.summary())\n","\n","vae_input = vae_encoder_input\n","vae_output = vae_decoder(vae_encoder_output)\n","vae_model = Model(vae_input, vae_output)\n","\n","\n","def r_loss(y_true, y_pred):\n","    r_loss = K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n","    return r_loss\n","\n","def kl_loss(y_true, y_pred):\n","    kl_loss =  -0.5 * tf.reduce_sum(1 + log_var - tf.square(mean_mu) - tf.exp(log_var), axis = 1)\n","    return kl_loss\n","\n","def total_loss(y_true, y_pred):\n","    return LOSS_FACTOR*r_loss(y_true, y_pred) + kl_loss(y_true, y_pred)\n","  \n","adam_optimizer = Adam(lr = LEARNING_RATE)\n","\n","vae_model.compile(optimizer=adam_optimizer, loss = total_loss, metrics = ['accuracy', r_loss, kl_loss])\n","\n","batch_size = 128\n","\n","loss_dis = []\n","r_loss_plot = []\n","kl_loss_plot = []\n","acc_dis = []\n","plot_iteration = []\n","\n","for i in range(1, epochs_number_1 + 1):\n","    images_train_x = get_random_batch(train_x, batch_size)\n","    images_train_y = get_random_batch(train_y, batch_size)\n","\n","    train_z = np.concatenate((images_train_x, images_train_y))\n","\n","    d_stats = vae_model.train_on_batch(x= train_z, y= train_z)\n","    loss_dis.append(d_stats[0])\n","    acc_dis.append(d_stats[1])\n","    r_loss_plot.append(d_stats[2])\n","    kl_loss_plot.append(d_stats[3])\n","    plot_iteration.append(i)\n","\n","    if (i != 1) and (i % 10 == 0):\n","      print('setp: ' + str(i) + \", r_loss: \" + str(r_loss_plot[i-1]) + \", kl_loss: \" + str(kl_loss_plot[i-1]) + \", total_loss: \" + str(loss_dis[i-1]))\n","\n","    if (i !=1)and (i % 50 == 0):\n","\n","      (fig, (ax1)) = plt.subplots(1)\n","      fig.set_size_inches(8, 8)\n","\n","      ax1.plot(plot_iteration, loss_dis, label=\"total loss\")\n","      ax1.legend()\n","\n","      ax1.plot(plot_iteration, r_loss_plot, \"C1\", label=\"r_loss\")\n","      ax1.legend()\n","\n","      ax1.plot(plot_iteration, kl_loss_plot, \"C2\", label=\"kl_loss\")\n","      ax1.legend()\n","\n","      plt.show()\n","\n","      (fig, (ax1)) = plt.subplots(1)\n","      fig.set_size_inches(8, 8)\n","\n","      ax1.plot(plot_iteration, acc_dis, \"C1\", label=\"accuracy\")\n","      ax1.legend()\n","\n","      plt.show()\n","          \n","    if (i !=1) and (i % 50 == 0):\n","\n","      test_sample_X = get_random_batch(train_x, 4)\n","      test_sample_Y = get_random_batch(train_y, 4)\n","\n","      visualize(test_sample_X, test_sample_Y, vae_encoder, vae_decoder, value_range)\n","\n","vae_encoder.save(save_path + \"encoder_\" + str(i) + \".h5\")\n","vae_decoder.save(save_path + \"decoder_XY_\" + str(i) + \".h5\")\n","\n","layer_number = 0\n","for layer in vae_encoder.layers:\n","  layer_number += 1\n","  print(\"Layer: \" + str(layer_number))\n","  layer.trainable = False\n","\n","# # # # # # VAE end training 1 # # # # # #\n","\n","# # # # # # VAE training 2 # # # # # #\n","\n","vae2_decoder_input, vae2_decoder_output, vae2_decoder = build_decoder(IMG_SHAPE, code_size)\n","print(vae2_decoder.summary())\n","\n","vae2_output = vae2_decoder(vae_encoder_output)\n","vae2_model = Model(vae_input, vae2_output)\n","\n","vae2_model.compile(optimizer=adam_optimizer, loss = total_loss, metrics = ['accuracy'])\n","\n","loss_dis = []\n","acc_dis = []\n","plot_iteration = []\n","\n","for i in range(1, epochs_number_2 + 1):\n","    images_train_y = get_random_batch(train_y, batch_size)\n","\n","    d_stats = vae2_model.train_on_batch(x= images_train_y, y= images_train_y)\n","    loss_dis.append(d_stats[0])\n","    acc_dis.append(d_stats[1])\n","    plot_iteration.append(i)\n","\n","    if (i !=1)and (i % 50 == 0):\n","\n","      (fig, (ax1)) = plt.subplots(1)\n","      fig.set_size_inches(8, 8)\n","\n","      ax1.plot(plot_iteration, loss_dis, label=\"loss discriminator\")\n","      ax1.legend()\n","\n","      plt.show()\n","\n","      (fig, (ax1)) = plt.subplots(1)\n","      fig.set_size_inches(8, 8)\n","\n","      ax1.plot(plot_iteration, acc_dis, \"C1\", label=\"acc discriminator\")\n","      ax1.legend()\n","\n","      plt.show()\n","          \n","    if (i !=1) and (i % 50 == 0):\n","\n","      test_sample_X = get_random_batch(train_x, 4)\n","      test_sample_Y = get_random_batch(train_y, 4)\n","\n","      visualize(test_sample_X, test_sample_Y, vae_encoder, vae2_decoder, value_range)\n","\n","    if (i > 99) and (i % 50 == 0):\n","      vae2_decoder.save(save_path + \"decoder_Y_\" + str(i) + \".h5\")\n","\n","# # # # # # # VAE end training 2 # # # # # #\n","\n","# # # # # # VAE training 3 # # # # # #\n","\n","vae3_decoder_input, vae3_decoder_output, vae3_decoder = build_decoder(IMG_SHAPE, code_size)\n","print(vae3_decoder.summary())\n","\n","vae3_output = vae3_decoder(vae_encoder_output)\n","vae3_model = Model(vae_input, vae3_output)\n","\n","vae3_model.compile(optimizer=adam_optimizer, loss = total_loss, metrics = ['accuracy'])\n","\n","loss_dis = []\n","acc_dis = []\n","plot_iteration = []\n","\n","for i in range(1, epochs_number_2 + 1):\n","    images_train_x = get_random_batch(train_x, batch_size)\n","\n","    d_stats = vae3_model.train_on_batch(x= images_train_x, y= images_train_x)\n","    loss_dis.append(d_stats[0])\n","    acc_dis.append(d_stats[1])\n","    plot_iteration.append(i)\n","\n","\n","    if (i !=1)and (i % 50 == 0):\n","\n","      (fig, (ax1)) = plt.subplots(1)\n","      fig.set_size_inches(8, 8)\n","\n","      ax1.plot(plot_iteration, loss_dis, label=\"loss discriminator\")\n","      ax1.legend()\n","\n","      plt.show()\n","\n","      (fig, (ax1)) = plt.subplots(1)\n","      fig.set_size_inches(8, 8)\n","\n","      ax1.plot(plot_iteration, acc_dis, \"C1\", label=\"acc discriminator\")\n","      ax1.legend()\n","\n","      plt.show()\n","          \n","    if (i !=1) and (i % 50 == 0):\n","\n","      test_sample_X = get_random_batch(train_x, 4)\n","      test_sample_Y = get_random_batch(train_y, 4)\n","\n","      visualize(test_sample_X, test_sample_Y, vae_encoder, vae3_decoder, value_range)\n","\n","    if (i > 99) and (i % 50 == 0):\n","      vae3_decoder.save(save_path + \"decoder_X_\" + str(i) + \".h5\")\n","\n","# # # # # # # VAE end training 3 # # # # # #\n","\n","print(\"Program finished successfully!\")"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}